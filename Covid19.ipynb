{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import folium\n",
    "import seaborn as sns\n",
    "from folium.plugins import TimestampedGeoJson\n",
    "\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import optimize\n",
    "#%load_ext line_profiler #%lprun -f help help()\n",
    "explore_data=False\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "ts_path='csse_covid_19_data/csse_covid_19_time_series/'\n",
    "df_deaths=pd.read_csv(ts_path+'time_series_19-covid-Deaths.csv')\n",
    "df_recovered=pd.read_csv(ts_path+'time_series_19-covid-Recovered.csv')\n",
    "df_confirmed=pd.read_csv(ts_path+'time_series_19-covid-Confirmed.csv')\n",
    "# Explore data\n",
    "if(explore_data==True):\n",
    "    print('Describe Confirmed')\n",
    "    display(describe(df_confirmed))\n",
    "    print('Describe Confirmed')\n",
    "    display(df_confirmed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function\n",
    "def describe(df):\n",
    "    return pd.concat([df.describe().T,df.sum().rename('sum')], axis=1).T\n",
    "def indloc(df,field,values):\n",
    "    return(df[df.index.get_level_values(field).isin(values)])\n",
    "def format_input(df,name): \n",
    "    df.rename(columns={'Province/State':'subregion','Country/Region':'region','Lat':'lat','Long':'long'},inplace=True)\n",
    "    df['subregion'].fillna(df['region']+'_country',inplace=True)\n",
    "    df = df.set_index(['subregion','region','lat','long']).stack()\n",
    "    df.index.names = ['subregion','region','lat','long','dates']\n",
    "    df.name = name\n",
    "    df = df.reset_index()\n",
    "    df['dates'] = pd.to_datetime(df['dates'],format='%m/%d/%y')\n",
    "    return(df)\n",
    "\n",
    "class Parameter:\n",
    "    def __init__(self, value):\n",
    "            self.value = value\n",
    "\n",
    "    def set(self, value):\n",
    "            self.value = value\n",
    "\n",
    "    def __call__(self):\n",
    "            return self.value\n",
    "\n",
    "def fit(function, parameters, y, x = None):\n",
    "    def f(params):\n",
    "        i = 0\n",
    "        for p in parameters:\n",
    "            p.set(params[i])\n",
    "            i += 1\n",
    "        return y - function(x)\n",
    "\n",
    "    if x is None: x = np.arange(y.shape[0])\n",
    "    p = [param() for param in parameters]\n",
    "    return optimize.leastsq(f, p)\n",
    "def latest_data(df):\n",
    "    temp = df.reset_index('dates')\n",
    "    return(temp[temp['dates']==temp['dates'].max()])\n",
    "\n",
    "\n",
    "# Calculate Doubling Rates\n",
    "def doubling_rate(df,agg_level):\n",
    "    def base2_exp(x): \n",
    "        return a()+(x-c()) * np.log(2) / b()\n",
    "    lookback = 10000\n",
    "    sample_size = 10\n",
    "    double_rate=[]\n",
    "    df = df[df['days_since_200']>-sample_size]\n",
    "\n",
    "    for index,group in  df.reset_index().groupby(agg_level)[['days','confirmed']]:\n",
    "        maxdays = group['days'].max()\n",
    "        for day in range(maxdays,maxdays-lookback,-1): #calculate doubling rate each day starting 15 days ago\n",
    "            x_data = np.asarray(group['days'].values)\n",
    "            y_data = np.asarray(np.log(group['confirmed'].values))\n",
    "            filters = np.argwhere((x_data<=day) & (x_data>day-sample_size)).T[0] #Use last 10 data points for fit\n",
    "\n",
    "            x_data = x_data[filters]; y_data = y_data[filters]\n",
    "            a = Parameter(1);b = Parameter(1.333);c = Parameter(0)\n",
    "\n",
    "            if(len(x_data)<sample_size):\n",
    "                break\n",
    "            \n",
    "            my_fit = fit(base2_exp, [a,b,c], y_data,x_data)\n",
    "            rate = my_fit[0][1]\n",
    "            if(rate==1.333):\n",
    "                rate=np.nan\n",
    "            else:\n",
    "                rate=round(rate,2)\n",
    "            double_rate.append({agg_level:index,'days':day,'Doubling Rate':rate})\n",
    "\n",
    "    return(pd.DataFrame(double_rate))\n",
    "\n",
    "def color_producer(rate):\n",
    "    color_scale = np.array(['#67001f','#b2182b','#d6604d','#f4a582','#fddbc7','#f7f7f7','#d1e5f0','#92c5de','#4393c3','#2166ac','#053061'])\n",
    "    scale=1\n",
    "    col=''\n",
    "    if(np.isnan(rate)):\n",
    "        col='grey'\n",
    "    else:\n",
    "        if(rate<=0):\n",
    "            col=color_scale[0]\n",
    "        for i in range(1,10):\n",
    "            if(i/scale<=rate and rate<(i+1)/scale):\n",
    "                col=color_scale[i]\n",
    "        if(rate>=10/scale):\n",
    "            col=color_scale[10]\n",
    "    return(col)\n",
    "def rgb(minimum, maximum, value):\n",
    "    minimum, maximum = float(minimum), float(maximum)\n",
    "    ratio = 2 * (value-minimum) / (maximum - minimum)\n",
    "    b = int(max(0, 255*(1 - ratio)))\n",
    "    r = int(max(0, 255*(ratio - 1)))\n",
    "    g = 255 - b - r\n",
    "    return r, g, b\n",
    "\n",
    "def repair_colonizers(df):\n",
    "    df = df.reset_index(drop=True)\n",
    "    colonizers = df[df['region']==df['subregion']]['region'].unique()\n",
    "    colonized = df[(df['region'].isin(colonizers)) & (df['region']!=df['subregion'])]['subregion'].unique()\n",
    "    for i,row in df.iterrows():\n",
    "\n",
    "        if(row['subregion'] in colonized):\n",
    "            df.at[i,'region'] = df.at[i,'subregion']        \n",
    "            df.at[i,'subregion'] = df.at[i,'subregion']+'_country'        \n",
    "        if((row['region'] in colonizers) & (row['region']==row['subregion'])):\n",
    "            df.at[i,'subregion'] = df.at[i,'subregion']+'_country'\n",
    "    return(df)\n",
    "\n",
    "def create_geojson_features(df):\n",
    "    print('> Creating GeoJSON features...')\n",
    "    features = []\n",
    "    for _, row in df.iterrows():\n",
    "        \n",
    "        \n",
    "        feature = {\n",
    "            'type': 'Feature',\n",
    "            'geometry': {\n",
    "                'type':'Point', \n",
    "                'coordinates':[row['long'],row['lat']]\n",
    "            },\n",
    "            'properties': {\n",
    "                'time': row['dates'].__str__(),\n",
    "                'style': {'color' : color_producer(row['Doubling Rate'])},\n",
    "                'icon': 'circle',\n",
    "                'popup':'{} <br> cases: {} <br> death: {} ({}%)  <br> recovery: {} <br> days2double: {}'.format(row['subregion'],\n",
    "                                                                                                                row['confirmed'],\n",
    "                                                                                                                row['death'],\n",
    "                                                                                                                row['death_pc'],\n",
    "                                                                                                                row['recovered'],\n",
    "                                                                                                                row['Doubling Rate']),\n",
    "                'iconstyle':{\n",
    "                    'fillColor': color_producer(row['Doubling Rate']),\n",
    "                    'fillOpacity': 0.8,\n",
    "                    'stroke': 'false',\n",
    "                    'radius': float(np.log(row['confirmed']+1))\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        features.append(feature)\n",
    "    return features\n",
    "\n",
    "def make_map(features):\n",
    "    print('> Making map...')\n",
    "    my_map = folium.Map(location=[20,0],height='100%', control_scale=True,  zoom_start=1.6)\n",
    "#    coords_belgium=[50.5039, 4.4699]\n",
    "#    pollution_map = folium.Map(location=coords_belgium, control_scale=True, zoom_start=8)\n",
    "\n",
    "    TimestampedGeoJson(\n",
    "        {'type': 'FeatureCollection',\n",
    "        'features': features}\n",
    "        , period='P1D'\n",
    "        , add_last_point=True\n",
    "        , auto_play=False\n",
    "#        , transition_time=10\n",
    "        , loop=False\n",
    "        , duration='P1D'\n",
    "        , max_speed=50\n",
    "        , loop_button=True\n",
    "        , date_options='YYYY/MM/DD'\n",
    "        , time_slider_drag_update=True\n",
    "    ).add_to(my_map)\n",
    "    print('> Done.')\n",
    "    return my_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_cols = ['subregion','region','lat','long','dates']\n",
    "df_all = format_input(df_deaths,'death')\n",
    "df_all = pd.merge(df_all,format_input(df_recovered,'recovered'),right_on=join_cols,left_on=join_cols)\n",
    "df_all = pd.merge(df_all,format_input(df_confirmed,'confirmed'),right_on=join_cols,left_on=join_cols)\n",
    "df_all = repair_colonizers(df_all)\n",
    "df_all = df_all.groupby(join_cols).sum()\n",
    "\n",
    "\n",
    "# Define days passed since beginning of dataset\n",
    "temp = df_all.reset_index(['region','lat','long','dates'])\n",
    "pivotalDates = temp.groupby('subregion')['dates'].min()\n",
    "temp['days'] = temp.merge(pivotalDates,how='left',on=['subregion'],suffixes=('', '_r')).apply(lambda x: (x['dates']-x['dates_r']).days,axis=1).fillna(0)\n",
    "df_all = temp.set_index(['region','lat','long','dates'],append=True)\n",
    "\n",
    "# Define data at various subgroups\n",
    "df_region = df_all.reset_index(['lat','long']).groupby(['region','dates']).agg({'death':sum,'recovered':sum,'confirmed':sum,'lat':np.mean,'long':np.mean,'days':max})\n",
    "df_region['death_pc'] = round(df_region['death']/df_region['confirmed']*100,2)\n",
    "df_all['death_pc'] = round(df_all['death'] /df_all['confirmed']*100,2)\n",
    "\n",
    "# Define days passed since confirmed cases reached 200\n",
    "temp = df_region.reset_index('dates')\n",
    "pivotalDates = temp[temp['confirmed']>200].groupby('region')['dates'].min()\n",
    "temp['days_since_200'] = temp.merge(pivotalDates,how='left',on=['region'],suffixes=('', '_r')).apply(lambda x: (x['dates']-x['dates_r']).days,axis=1)\n",
    "df_region = temp.set_index('dates',append=True)\n",
    "temp = df_all.reset_index(['region','lat','long','dates'])\n",
    "pivotalDates = temp[temp['confirmed']>200].groupby('subregion')['dates'].min()\n",
    "temp['days_since_200'] = temp.merge(pivotalDates,how='left',on=['subregion'],suffixes=('', '_r')).apply(lambda x: (x['dates']-x['dates_r']).days,axis=1).fillna(0)\n",
    "df_all = temp.set_index(['region','lat','long','dates'],append=True)\n",
    "\n",
    "\n",
    "# Calculate Doubling Rates\n",
    "df_all = df_all.reset_index().merge(doubling_rate(df_all,'subregion'),how='left',on=['subregion','days']).set_index(['subregion','region','lat','long','dates'])\n",
    "df_region = df_region.reset_index().merge(doubling_rate(df_region,'region'),how='left',on=['region','days']).set_index(['region','dates'])\n",
    "df_all['days'] = df_all['days'].astype(int)\n",
    "df_region['days'] = df_region['days'].astype(int)\n",
    "\n",
    "#Define material data at various subgroups levels\n",
    "material_countries = list(df_region.groupby(['region']).max().nlargest(6,'confirmed').index)\n",
    "[material_countries.append(i) for i in ['Canada','Argentina']]\n",
    "\n",
    "df_all_material = indloc(df_all,'region',material_countries)\n",
    "df_region_material = indloc(df_region,'region',material_countries)\n",
    "\n",
    "# Today's data\n",
    "df_all_today = latest_data(df_all)\n",
    "df_region_today = latest_data(df_region)\n",
    "\n",
    "\n",
    "\n",
    "# Reference curves\n",
    "max_days_since_200=df_region[['days_since_200']].max().values[0]\n",
    "reference_curve = pd.DataFrame([i for i in range(int(max_days_since_200)+1)],columns=['days_since_200'])\n",
    "reference_curve['30% per day']=reference_curve['days_since_200'].apply(lambda x: 200*1.30**x)\n",
    "reference_curve['100% per 4 days ']=reference_curve['days_since_200'].apply(lambda x: 200*math.pow(2,x/4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Doubling Rates\n",
    "fig,ax = plt.subplots(figsize=(15,5))\n",
    "temp = df_region_material[df_region_material['days_since_200']>=0]\n",
    "temp = temp.reset_index('dates').set_index('days_since_200',append=True)\n",
    "temp['Doubling Rate'].unstack('region').plot(ax=ax)\n",
    "plt.ylim(0,10)\n",
    "plt.ylabel('days until cases double')\n",
    "plt.xlabel('# days since 200$^{\\mathrm{th}}$ case')\n",
    "plt.grid(which='both')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log scale confirmed cases\n",
    "fig,ax = plt.subplots(figsize=(15,7))\n",
    "ax.set_yscale('log')\n",
    "temp = df_region_material[df_region_material['days_since_200']>=0].set_index('days_since_200',append=True)\n",
    "temp.groupby(['region','days_since_200'])['confirmed'].max().unstack(['region']).plot(ax=ax)\n",
    "reference_curve.set_index('days_since_200').plot(ax=ax)\n",
    "plt.grid(True,axis='both',which='both')\n",
    "plt.ylabel(\"# Confirmed Cases\")\n",
    "plt.xlabel(\"# days since 200$^{\\mathrm{th}}$ case\")\n",
    "plt.ylim(200,10**5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Map\n",
    "data=df_all.reset_index()\n",
    "df = df_region.reset_index()\n",
    "missing_countries = data[~data['subregion'].str.contains('_country')]['region'].unique()\n",
    "df = df[df['region'].isin(missing_countries)]\n",
    "df['subregion'] = df['region']+'_country'\n",
    "data = data.append(df[data.columns],ignore_index=True).reset_index(drop=True)\n",
    "\n",
    "m = []\n",
    "for i in range(0,2):\n",
    "    if(i==0):\n",
    "        filter =data['subregion'].str.contains('_country')\n",
    "        name = 'covid19_countries.html'\n",
    "    if(i==1):\n",
    "        filter =~data['subregion'].str.contains('_country')\n",
    "        name = 'covid19_cities.html'\n",
    "        \n",
    "    data_region = data[filter]\n",
    "    data_region['subregion'] = data_region['subregion'].replace('_country','')\n",
    "    features_region = create_geojson_features(data_region)\n",
    "    m_region = make_map(features_region)\n",
    "    m.append(m_region)\n",
    "    m_region.save(name)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
