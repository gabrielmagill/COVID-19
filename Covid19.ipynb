{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COVID 19 Jupyter Dashboard\n",
    "This notebook reads in COVID19 data maintained by John Hopkins Universities and creates a dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import folium\n",
    "import os,sys\n",
    "import seaborn as sns\n",
    "from folium.plugins import TimestampedGeoJson\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import optimize\n",
    "from scipy.optimize import curve_fit\n",
    "pd.set_option('display.max_rows', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### PATHS ####\n",
    "output='output/'\n",
    "\n",
    "#### HELPER FUNCTIONS ####\n",
    "def describe(df):\n",
    "    return pd.concat([df.describe().T,df.sum().rename('sum')], axis=1).T\n",
    "def indloc(df,field,values):\n",
    "    return(df[df.index.get_level_values(field).isin(values)])\n",
    "\n",
    "\n",
    "\n",
    "#### LOADING AND PRE-PROCESSING ####\n",
    "def load_data():\n",
    "    explore_data=False\n",
    "    ts_path=sys.path[0]+'/csse_covid_19_data/csse_covid_19_time_series/'\n",
    "    df_deaths=pd.read_csv(ts_path+'time_series_covid19_deaths_global.csv')\n",
    "    df_recovered=pd.read_csv(ts_path+'time_series_covid19_recovered_global.csv')\n",
    "    df_confirmed=pd.read_csv(ts_path+'time_series_covid19_confirmed_global.csv')\n",
    "    # Explore data\n",
    "    if(explore_data==True):\n",
    "        print('Describe Confirmed')\n",
    "        display(describe(df_confirmed))\n",
    "        print('Describe Confirmed')\n",
    "        display(df_confirmed.head())\n",
    "    return df_deaths,df_recovered,df_confirmed\n",
    "\n",
    "def uncolonize(df):\n",
    "    df_helper = df.groupby('region').filter(lambda x: len(x)>1 and any(x['subregion'].isna()))\n",
    "    colonizers = df_helper['region'].unique()\n",
    "    colonized = df_helper['subregion'].unique()\n",
    "\n",
    "    # and we give it back to you... the people\n",
    "    for i,row in df.iterrows():\n",
    "        if(row['subregion'] in colonized):\n",
    "            df.at[i,'region'] = df.at[i,'subregion']        \n",
    "            df.at[i,'subregion'] = np.nan        \n",
    "\n",
    "    return(df)\n",
    "\n",
    "\n",
    "def format_input(df,name): \n",
    "    df.rename(columns={'Province/State':'subregion','Country/Region':'region','Lat':'lat','Long':'long'},inplace=True)\n",
    "    df = uncolonize(df)\n",
    "    df['subregion'].fillna(df['region']+'_country',inplace=True)\n",
    "\n",
    "    df = df.set_index(['subregion','region','lat','long']).stack()\n",
    "    df.index.names = ['subregion','region','lat','long','dates']\n",
    "    df.name = name\n",
    "    df = df.reset_index()\n",
    "    df['dates'] = pd.to_datetime(df['dates'],format='%m/%d/%y')\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def combine_data(df_deaths,df_confirmed,df_recovered):\n",
    "    join_cols = ['subregion','region','lat','long','dates']\n",
    "    df_all = format_input(df_deaths,'death')\n",
    "    df_all = pd.merge(df_all,format_input(df_confirmed,'confirmed'),on=join_cols,how='outer')\n",
    "    df_all = pd.merge(df_all,format_input(df_recovered,'recovered'),on=join_cols,how='outer')\n",
    "    df_all = df_all.groupby(join_cols).sum().reset_index()\n",
    "\n",
    "    return df_all\n",
    "\n",
    "def augment_dataset(df, level):\n",
    "\n",
    "    # Add # active cases\n",
    "    df['active'] = df['confirmed'] - df['death'] - df['recovered']\n",
    "    \n",
    "    # Add day count column\n",
    "    pivotalDates = df.groupby(level)['dates'].min()\n",
    "    df['days'] = df.merge(pivotalDates,how='left',on=[level],suffixes=('', '_r')).apply(lambda x: (x['dates']-x['dates_r']).days,axis=1).fillna(0)\n",
    "    df['days'] = df['days'].astype(int)\n",
    "\n",
    "    # Add days since 200th case\n",
    "    pivotalDates = df[df['confirmed']>200].groupby(level)['dates'].min()\n",
    "    df['days_since_200'] = df.merge(pivotalDates,how='left',on=[level],suffixes=('', '_r')).apply(lambda x: (x['dates']-x['dates_r']).days,axis=1).fillna(0)\n",
    "    df['days_since_200'] = df['days_since_200'].astype(int)\n",
    "    \n",
    "    # Add deltas\n",
    "    columns = ['confirmed','death','recovered']\n",
    "    df_deltas = df.groupby([level,'dates'])[columns].sum()\n",
    "    df_deltas = df_deltas.groupby(level)[columns].diff()\n",
    "    df_deltas.rename(columns={'confirmed':'confirmed_delta',\n",
    "                              'death':'death_delta',\n",
    "                              'recovered':'recovered_delta'}\n",
    "                     ,inplace=True)\n",
    "    df = df.merge(df_deltas, how='left',on=[level,'dates'])\n",
    "\n",
    "\n",
    "    \n",
    "    # Add % Death\n",
    "    df['death_pc'] = round(df['death'] /df['confirmed']*100,2)\n",
    "\n",
    "    # Add doubling rate\n",
    "    df = df.merge(doubling_rate(df,level),how='left',on=[level,'days'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "def material_countries(df,additional):\n",
    "    material_countries = list(df.groupby('region').max().nlargest(6,'confirmed').index)\n",
    "    [material_countries.append(i) for i in additional]\n",
    "\n",
    "    df = df[df['region'].isin(material_countries)]\n",
    "\n",
    "    return df\n",
    "\n",
    "def latest_data(df):\n",
    "    return(df[df['dates']==df['dates'].max()])\n",
    "\n",
    "\n",
    "#### EXPONENTIAL FITTING ####\n",
    "def line(x,a,b): \n",
    "    return a*x+b\n",
    "\n",
    "def get_doubling_rate(x):\n",
    "    zero=0.000000001\n",
    "    if((x[0]<=zero) and (x[0]>=-zero)):\n",
    "        return np.nan\n",
    "    else:\n",
    "        # Solve for c by looking at coefficient of x\n",
    "        # log[d 2^(x/c-f/c)] = a x + b\n",
    "        return np.log(2)/x[0]\n",
    "\n",
    "def doubling_rate(df,agg_level):\n",
    "\n",
    "    lookback = 1000\n",
    "    sample_size = 15\n",
    "    double_rate=[]\n",
    "\n",
    "    for index,group in  df.groupby(agg_level)[['days','confirmed']]:\n",
    "        maxdays = group['days'].max()\n",
    "        for day in range(maxdays,maxdays-lookback,-1):\n",
    "    \n",
    "            if(day<sample_size):\n",
    "                break\n",
    "            \n",
    "            x_data = group['days'].values\n",
    "            y_data = group['confirmed'].values\n",
    "\n",
    "            filters = np.argwhere((x_data<=day) & (x_data>=day-sample_size)).T[0] \n",
    "            \n",
    "            if(len(filters)<sample_size):\n",
    "                break\n",
    "            \n",
    "            x_data = x_data[filters]\n",
    "            y_data = y_data[filters]\n",
    "\n",
    "            if(np.any(y_data==0)):\n",
    "                break\n",
    "            else:\n",
    "                y_data = np.log(y_data)\n",
    "            \n",
    "            \n",
    "            popt, pcov = curve_fit(line, x_data, y_data,p0=[1.5,0])\n",
    "            rate = round(get_doubling_rate(popt),2)\n",
    "            double_rate.append({agg_level:index,'days':day,'doubling_rate':rate,'best_fit':popt})\n",
    "\n",
    "    return(pd.DataFrame(double_rate))\n",
    "\n",
    "\n",
    "\n",
    "#### INTERACTIVE MAPS ####\n",
    "\n",
    "def color_producer(rate):\n",
    "    color_scale = np.array(['#67001f','#b2182b','#d6604d','#f4a582','#fddbc7','#f7f7f7','#d1e5f0','#92c5de','#4393c3','#2166ac','#053061'])\n",
    "    scale=1\n",
    "    col=''\n",
    "    if(np.isnan(rate)):\n",
    "        col='grey'\n",
    "    else:\n",
    "        if(rate<=0):\n",
    "            col=color_scale[0]\n",
    "        for i in range(1,10):\n",
    "            if(i/scale<=rate and rate<(i+1)/scale):\n",
    "                col=color_scale[i]\n",
    "        if(rate>=10/scale):\n",
    "            col=color_scale[10]\n",
    "    return(col)\n",
    "\n",
    "\n",
    "def create_geojson_features(df,level):\n",
    "    print('> Creating GeoJSON features...')\n",
    "    features = []\n",
    "    for _, row in df.iterrows():\n",
    "        \n",
    "        \n",
    "        feature = {\n",
    "            'type': 'Feature',\n",
    "            'geometry': {\n",
    "                'type':'Point', \n",
    "                'coordinates':[row['long'],row['lat']]\n",
    "            },\n",
    "            'properties': {\n",
    "                'time': row['dates'].__str__(),\n",
    "                'style': {'color' : color_producer(row['doubling_rate'])},\n",
    "                'icon': 'circle',\n",
    "                'popup':'{} <br> cases: {} <br> death: {} ({}%)  <br> recovery: {} <br> days2double: {}'.format(row[level],\n",
    "                                                                                                                row['confirmed'],\n",
    "                                                                                                                row['death'],\n",
    "                                                                                                                row['death_pc'],\n",
    "                                                                                                                row['recovered'],\n",
    "                                                                                                                row['doubling_rate']),\n",
    "                'iconstyle':{\n",
    "                    'fillColor': color_producer(row['doubling_rate']),\n",
    "                    'fillOpacity': 0.8,\n",
    "                    'stroke': 'false',\n",
    "                    'radius': float(np.log(row['confirmed']+1))\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        features.append(feature)\n",
    "    return features\n",
    "\n",
    "def make_map(features):\n",
    "    print('> Making map...')\n",
    "    my_map = folium.Map(location=[20,0],height='100%', control_scale=True,  zoom_start=1.6)\n",
    "\n",
    "    TimestampedGeoJson(\n",
    "        {'type': 'FeatureCollection',\n",
    "        'features': features}\n",
    "        , period='P1D'\n",
    "        , add_last_point=True\n",
    "        , auto_play=False\n",
    "#        , transition_time=10\n",
    "        , loop=False\n",
    "        , duration='P1D'\n",
    "        , max_speed=50\n",
    "        , loop_button=True\n",
    "        , date_options='YYYY/MM/DD'\n",
    "        , time_slider_drag_update=True\n",
    "    ).add_to(my_map)\n",
    "    print('> Done.')\n",
    "    return my_map\n",
    "\n",
    "\n",
    "#### PLOTS ####\n",
    "def format_for_plot(df,level):\n",
    "    df = df[df['days_since_200']>=0]\n",
    "    df = df.set_index(['days_since_200',level]).unstack(level)\n",
    "    return(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "df_deaths,df_recovered,df_confirmed = load_data()\n",
    "df_all = combine_data(df_deaths,df_confirmed,df_recovered)\n",
    "df_all = augment_dataset(df_all,'subregion')\n",
    "\n",
    "# Region level view\n",
    "df_region = df_all.groupby(['region','dates']).agg({'death':sum,'recovered':sum,'confirmed':sum,'lat':np.mean,'long':np.mean}).reset_index()\n",
    "df_region = augment_dataset(df_region,'region')\n",
    "\n",
    "# Material countries only\n",
    "df_all_material = material_countries(df_all,['Canada','Argentina'])\n",
    "df_region_material = material_countries(df_region,['Canada','Argentina'])\n",
    "\n",
    "# Today's data only\n",
    "df_all_today = latest_data(df_all)\n",
    "df_region_today = latest_data(df_region)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick sanity check on best fits\n",
    "fig,ax = plt.subplots(figsize=(15,10));\n",
    "\n",
    "df = df_region_material.set_index(['days','region']).unstack('region')\n",
    "colors = ['b','g','r','c','m','y','k','orange']\n",
    "np.log(df[df['confirmed']>0]['confirmed']).plot(ax=ax,style=colors)\n",
    "\n",
    "dat=[]\n",
    "for index,row in df.iterrows():\n",
    "    if(index%20 == 0):\n",
    "        for name,v in row['best_fit'].iteritems():\n",
    "            try:\n",
    "                math.isnan(v)\n",
    "            except:\n",
    "                dat.append([[name,i,v[0]*i+v[1]] for i in range(index-15,index+1)])\n",
    "\n",
    "dat = [i for sublist in dat for i in sublist]\n",
    "df_calibrate = pd.DataFrame(dat,columns=['region','days','value'])\n",
    "df_calibrate = df_calibrate.set_index(['days','region']).unstack('region')['value']\n",
    "df_calibrate.plot(ax=ax,linestyle='dashed',style=colors);\n",
    "\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlim(30,64)\n",
    "ax.set_ylim(2,15)\n",
    "\n",
    "\n",
    "plt.grid(which='both')\n",
    "plt.savefig(output+'DoublingRate.Calibration.pdf')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Pre-process\n",
    "df_unstacked = format_for_plot(df_region_material,'region')\n",
    "xmax = int(df_unstacked.index.max()-20)\n",
    "\n",
    "df_ref = pd.DataFrame([i for i in range(xmax+1)],columns=['days_since_200'])\n",
    "df_ref['Doubles every 3 days']=df_ref['days_since_200'].apply(lambda x: 200*1.26**x)\n",
    "df_ref.set_index('days_since_200',inplace=True)\n",
    "\n",
    "df_ref.index.name = ''\n",
    "df_unstacked.index.name=''\n",
    "\n",
    "# Global properties\n",
    "fig, ax = plt.subplots(4, 1, sharex=True,figsize=(15,20))\n",
    "fig.add_subplot(111, frameon=False)\n",
    "plt.tick_params(labelcolor='none', top='off', bottom='off', left='off', right='off')\n",
    "plt.grid(False)\n",
    "plt.xlabel('# days since 200$^{\\mathrm{th}}$ case')\n",
    "\n",
    "# Total confirmed cases\n",
    "df_unstacked['confirmed'].plot(ax=ax[0])\n",
    "df_ref.plot(ax=ax[0])\n",
    "\n",
    "ax[0].set_xlim(0,xmax)\n",
    "ax[0].set_ylim(200,1000000)\n",
    "ax[0].set_ylabel('# cases')\n",
    "ax[0].set_yscale('log')\n",
    "ax[0].grid(which='major')\n",
    "\n",
    "# Daily confirmed deltas\n",
    "df_unstacked['confirmed_delta'].plot(ax=ax[1])\n",
    "ax[1].set_xlim(0,xmax)\n",
    "ax[1].set_ylim(10,50000)\n",
    "ax[1].set_ylabel('# new cases')\n",
    "ax[1].set_yscale('log')\n",
    "ax[1].grid(which='major')\n",
    "\n",
    "\n",
    "# Active Cases\n",
    "df_unstacked['active'].plot(ax=ax[2])\n",
    "ax[2].set_xlim(0,xmax)\n",
    "ax[2].set_ylim(100,200000)\n",
    "ax[2].set_ylabel('# active cases')\n",
    "ax[2].set_yscale('log')\n",
    "ax[2].grid(which='major')\n",
    "\n",
    "\n",
    "# Doubling rate\n",
    "df_unstacked['doubling_rate'].plot(ax=ax[3])\n",
    "ax[3].set_xlim(0,xmax)\n",
    "ax[3].set_ylim(0,10)\n",
    "ax[3].set_ylabel('# days until cases double')\n",
    "ax[3].grid(which='major')\n",
    "\n",
    "\n",
    "plt.savefig(output+'Covid19.figs.pdf')\n",
    "#plt.close()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Movies\n",
    "\n",
    "df = df_all[~df_all['subregion'].str.contains('_country')]\n",
    "m = make_map(create_geojson_features(df,'subregion'))\n",
    "m.save(output+'covid19_cities.html')\n",
    "\n",
    "df = df_region\n",
    "m = make_map(create_geojson_features(df,'region'))\n",
    "m.save(output+'covid19_countries.html')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
